{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your first CUDA code\n",
    "\n",
    "In this lab, you will learn how to adapt a code such that it uses the GPU. \n",
    "\n",
    "Lab created by EPCC, The University of Edinburgh. Documentation and source code copyright The University of Edinburgh 2016. Lab style and template created by NVIDIA, see https://nvidia.qwiklab.com/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "First, please try and execute the below command. Give focus to the cell by clicking on it, and then either press the play button above or press your Enter key whilst holding down Shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"This command is running on host $HOSTNAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The exercise provides a template solution in either C or Fortran.\n",
    "\n",
    "To edit a source file, we will use the notebook menus at the top right. You should still see\n",
    "the directory structure in the original tab in your browser. Nagivate to the appropriate source file in `src_c` or `src_fortran`. Click on the filename to enter the editor. Use the file menu at the top right to save an updated version of the file.\n",
    "\n",
    "The template source file is clearly marked with the sections to be edited, e.g.\n",
    "<code>\n",
    "/\\* Part 1A: allocate device memory \\*/\n",
    "</code>\n",
    "Please see below for instructions. Where necessary, you should refer to the CUDA C Programming Guide and Reference Manual documents available from\n",
    "http://developer.nvidia.com/nvidia-gpu-computing-documentation\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Copying Between Host and Device\n",
    "This simple CUDA code has the purpose of negating an array of integers. We introduce the important concepts of device-memory management and kernel invocation. The final version should copy an array of integers from the host to device, multiply each element by −1 on the device, and then copy the array back to the host.\n",
    "\n",
    "Choose the C or Fortran version by executing the corresponding cell below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "C:\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a link to the C version of the templates\n",
    "!rm -rf src; ln -s src_c src; echo \"Using C version\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "Fortran:\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a link to the Fortran version of the templates\n",
    "!rm -rf src; ln -s src_fortran src; echo \"Using Fortran version\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "<b>C:</b>\n",
    "\n",
    "\n",
    "Start from the intro.cu template.\n",
    "<li> 1A) Allocate memory for the array on the device: use the existing pointer <code>d_a</code> and the variable\n",
    "<code>sz</code> (which has already been assigned the size of the array in bytes).\n",
    "<li> 1B) Copy the array <code>h_a</code> on the host to <code>d_a</code> on the device.\n",
    "<li> 1C) Copy <code>d_a</code> on the device back to <code>h_out</code> on the host.\n",
    "<li> 1D) Free <code>d_a</code>.\n",
    "\n",
    "Execute the 2 cells below to compile and run the code (noting that the <code>arch</code> flag specifies the compute capability of the CUDA device).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "<b>Fortran:</b>\n",
    "\n",
    "\n",
    "Start from the intro.cuf template.\n",
    "<li> 1A) Allocate memory for the array on the device: use the existing pointer <code>d_a</code> and <code>ARRAY_SIZE</code> (which has already been assigned the size of the array in elements).\n",
    "<li> 1B) Copy the array <code>h_a</code> on the host to <code>d_a</code> on the device, using an appropriate assignment operation.\n",
    "<li> 1C) Copy <code>d_a</code> on the device back to <code>h_out</code> on the host, using another assignment operation.\n",
    "<li> 1D) Deallocate <code>d_a</code>.\n",
    "\n",
    "Execute the 2 cells below to compile and run the code (noting that the <code>Mcuda</code> flag specifies the compute capability of the CUDA device) \n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell to compile the code. Wait until \"Complete\" is printed in the output. \n",
    "!cd src; make clean; make; cd ..; echo \"Complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell to run the code. Wait until \"Complete\" is printed in the output.\n",
    "!cd src; ./intro; cd ..; echo \"Complete\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------\n",
    "The output (the contents of the h_out array) or any error messages will be printed. So far the code simply copies from h_a on the host to d_a on the device, then copies d_a back to h_out, so the‘ output should be the initial content of h_a — the numbers 0 to 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Launching Kernels\n",
    "--\n",
    "\n",
    "-----\n",
    "<b>C:</b>\n",
    "\n",
    "Now we will edit the intro.cu file to actually run a kernel on the GPU device.\n",
    "<li> 2A) Configure and launch the kernel using a 1D grid and a single thread block (<code>NUM_BLOCKS</code>\n",
    "and <code>THREADS_PER_BLOCK</code> are already defined for this case).\n",
    "<li> 2B) Implement the actual kernel function to negate an array element as follows:\n",
    "<code>\n",
    "    int idx = threadIdx.x;\n",
    "    d_a[idx] = -1 * d_a[idx];\n",
    "</code>\n",
    "\n",
    "<li> Compile and run the code by executing the above cells as before. This time the output should contain the result of negating each element of the input array. Because the array is initialised to the numbers 0 to 255, you should see the numbers 0 down to −255 printed.\n",
    "\n",
    "This kernel works, but since it only uses one thread block, it will only be utilising one of the multiple SMs available on the GPU. Multiple thread blocks are needed to fully utilize the available resources.\n",
    "<li> 2C) Implement the kernel again, this time allowing multiple thread blocks. It will be very similar to the previous kernel implementation except that the array index will be computed differently:\n",
    "<code>\n",
    "    int idx = threadIdx.x + (blockIdx.x * blockDim.x);\n",
    "</code>    \n",
    "Remember to also change the kernel invocation to invoke negate_multiblock this time. With this version you can change <code>NUM_BLOCKS</code> and <code>THREADS_PER_BLOCK</code> to have different values — so long as they still multiply to give the array size.\n",
    "\n",
    "-----\n",
    "<b>Fortran:</b>\n",
    "\n",
    "Now we will edit the intro.cuf and array_negate.cuf files to actually run a kernel on the GPU device.\n",
    "<li> 2A) Configure and launch the kernel using a 1D grid and a single thread block (<code>NUM_BLOCKS</code>\n",
    "and <code>THREADS_PER_BLOCK</code> are already defined for this case).\n",
    "<li> 2B) Implement the actual kernel function to negate an array element as follows:\n",
    "<code>\n",
    "integer :: idx\n",
    "\n",
    "idx = threadidx%x\n",
    "aa(idx) = -1*aa(idx)\n",
    "</code>\n",
    "\n",
    "<li> Compile and run the code by executing the above cells as before. This time the output should contain the result of negating each element of the input array. Because the array is initialised to the numbers 0 to 255, you should see the numbers 0 down to −255 printed.\n",
    "\n",
    "This kernel works, but since it only uses one thread block, it will only be utilising one of the multiple SMs available on the GPU. Multiple thread blocks are needed to fully utilize the available resources.\n",
    "<li> 2C) Implement the kernel again, this time allowing multiple thread blocks. It will be very similar to the previous kernel implementation except that the array index will be computed differently:\n",
    "<code>\n",
    "idx = threadidx%x + ((blockidx%x-1) * blockdim%x)\n",
    "</code>    \n",
    "Remember to also change the kernel invocation to invoke g_negate_multiblock this time. With this version you can change <code>NUM_BLOCKS</code> and <code>THREADS_PER_BLOCK</code> to have different values — so long as they still multiply to give the array size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Handling any size array\n",
    "\n",
    "At the moment we are insisting that the array size be an exact multiple of the block size. In general we should handle any size that will fit in GPU memory!\n",
    "\n",
    "Let the total number of elements be `N ` and the block size be `B`. Recall that in integer division we discard the fractional part so we can write:\n",
    "```\n",
    "N = k * B + r\n",
    "```\n",
    "i.e. `N` can divided into `k` (an integer) number of blocks, plus a remainder, `r`. If `r` is zero, then we need `k` blocks, else we need `k + 1`. This can be expressed in a simple formula:\n",
    "```\n",
    "nBlocks = ((N-1) / B) + 1\n",
    "```\n",
    "Convince yourself this is correct!\n",
    "\n",
    "* 3A) Update the kernel launch code to compute the number of blocks using this formula.\n",
    "\n",
    "What will happen in the last block with the current kernel?\n",
    "\n",
    "* 3B) Implement a condition in the kernel to protect against this.\n",
    "\n",
    "Try changing `ARRAY_SIZE` to a non-multiple of 256 (e.g 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"finished early\"></a>\n",
    "## Finally...\n",
    "\n",
    "The <code>deviceQuery</code> utility queries the properties of the GPUs on the system. Execute the below cell and inspect the output.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/usr/local/home/course/deviceQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now add the text <code>export CUDA_VISIBLE_DEVICES=1,2;</code> to the line above (between the the ! and the <code>/usr</code>), and re-execute. Try again with <code>export CUDA_VISIBLE_DEVICES=1</code>. Try and work out what has happened."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"post-lab\"></a>\n",
    "## Post-Lab\n",
    "\n",
    "Finally, you may save your work from this lab before the end of the course.\n",
    "\n",
    "From the file menu at the top right of the editor tab, click download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "p.hint_trigger{\n",
    "  margin-bottom:7px;\n",
    "  margin-top:-5px;\n",
    "  background:#64E84D;\n",
    "}\n",
    ".toggle_container{\n",
    "  margin-bottom:0px;\n",
    "}\n",
    ".toggle_container p{\n",
    "  margin:2px;\n",
    "}\n",
    ".toggle_container{\n",
    "  background:#f0f0f0;\n",
    "  clear: both;\n",
    "  font-size:100%;\n",
    "}\n",
    "</style>\n",
    "<script>\n",
    "$(\"p.hint_trigger\").click(function(){\n",
    "   $(this).toggleClass(\"active\").next().slideToggle(\"normal\");\n",
    "});\n",
    "   \n",
    "$(\".toggle_container\").hide();\n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
